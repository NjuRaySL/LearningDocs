# Redis

## 基础

### Redis概念

Redis 是⼀种**基于内存的数据库**

**读写速度非常快，常用于缓存，消息队列、分布式锁等场景**。

Redis 提供了多种数据类型：，**⽐如 String(字符串)、 Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、 HyperLogLog（基数统计）、GEO（地理信息）**、Stream（流）。

**Redis 还支持事务 、持久化**、Lua 脚本、**多种集群方案**（主从复制模式、哨兵模式、切⽚机群模式）、发布/订阅模式，**内存淘汰机制、过期删除机制**等等。

### Redis 和 Memcached 有什么区别？

- **Redis支持的数据类型更丰富**
- **Redis支持数据的持久化，重启后可以继续使用**
- **Redis支持原生集群模式**
- **Redis支持Lua脚本，发布/订阅模型和事务等**

### Redis 作为 MySQL 的缓存？

Redis 具备**「⾼性能」和「⾼并发」**两种特性

- **直接访问 Redis 能够承受的请求是远远⼤于直接访问 MySQL 的**，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样⽤户的⼀部分请求会直接到缓存这⾥而不用经过数据库

### Redis线程模型

Redis单线程指的是**「接收客户端请求->解析请求 ->进⾏数据读写等操作->发送数据给客户端」这个过程是由⼀个线程（主线程）来完成的**

Redis并不是单线程的：

- Redis为「关闭⽂件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理**

- **异步释放Redis也就是 lazyfree线程用来删除大Key**

### 为什么Redis这么快（重）

- **大部分操作都在内存完成**，Redis 瓶颈可能是机器的内存或者网络带宽，不是CPU
- **采⽤单线程模型可以避免了多线程之间的竞争**
- **采⽤了 I/O 多路复⽤机制处理⼤量的客户端 Socket 请求**

### 之前单线程/之后多线程

**之前单线程原因：**

- CPU 并不是制约Redi 性能表现的瓶颈所在
- 多线程增加复杂度，资源消耗难维护，可能出现死锁

**之后多线程原因：**

- 因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在⽹络 I/O 的处理上。**为了提⾼⽹络 I/O 的并⾏度，Redis 6.0 对于⽹络 I/O 采⽤多线程来处理**

- **对于命令的执⾏，Redis 仍然使用单线程来处理**

### 如何设计⼀个缓存策略，可以动态缓存热点数据

总体思路：

**通过数据最新访问时间来做排名，并过滤 掉不常访问的数据，只留下经常访问的数据。**

### 常⻅的缓存更新策略？

常见的缓存更新策略共有3种： 

- **Cache Aside（旁路缓存）策略；** 
- **Read/Write Through（读穿 / 写穿）策略；** 
- **Write Back（写回）策略；**

------

Cache Aside（旁路缓存）策略：

- 写策略：**先更新数据库中的数据，再删除缓存中的数据（注意顺序）**
- 读策略：**如果读取的数据命中了缓存，则直接返回数据； 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写⼊到 缓存，并且返回给⽤户**。

Read/Write Through（读穿 / 写穿）策略：

- **Read Through 策略：**先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组 件负责从数据库查询数据，并将结果写⼊到缓存组件，最后缓存组件将数据返 回给应⽤
- **Write Through 策略：**
- - 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应⽤程序更新完成。 
  - 如果缓存中数据不存在，直接更新数据库，然后返回

Write Back（写回）策略：

- **在更新数据的时候，只更新缓存，同时将缓存数据设 置为脏的，然后立马返回，并不会更新数据库。**

### Redis 如何实现延迟队列？

在 Redis可以使⽤有序集合（ZSet）的⽅式来实现延迟消息队列的

ZSet **有⼀个 Score 属性可以⽤来存储延迟执行的时间**

### Redis 的大key 如何处理？

大key 并不是指 key 的值很大，**而是 key 对应的 value 很⼤。**

**如何找到大key？**

- redis-cli --bigkeys 查找大key
- 使用SCAN命令查找大key

**如何删除大key?**

- **分批次删除**
- **异步删除：放在异步线程删除，不会阻塞**

### Redis管道有什么用？

⼀种批处理技术，**一次处理多个 Redis 命令**，从⽽提⾼整个交互的性能

**可以解决多个命令执行时的网络等待**

### Redis 事务支持回滚吗？

**Redis 中并没有提供回滚机制**，

- 虽然 Redis 提供了 DISCARD 命令，但是这个命令**只能⽤来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果**
- **已经执行的命令没办法回退，不能保证原子性**

### 如何用Redis实现分布式锁的

**分布式锁是用于分布式环境下并发控制的⼀种机制，⽤于控制某个资源在同⼀时刻只能被⼀个应用所使用**

Redis的SET命令有个 NX 参数可以实现「key不存在才插⼊」，所以可以用它来实现分布式锁： 

- **如果 key 不存在，则显示插⼊成功，可以⽤来表示加锁成功；** 
- **如果 key 存在，则会显示插⼊失败，可以⽤来表示加锁失败。**

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满⾜三个条件。 

- **加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作**，但需要以原子操作的⽅式完成，所以，我们使用SET命令带上 NX 选项来实现加锁； 
- **锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁⼀直无法释放**，所以，我们在SET命令执⾏时加上EX/PX选项，设置其过期时间； 
- **锁变量的值需要能区分来⾃不同客户端的加锁操作，以免在释放锁时，出现误释放操作**，所以，我们使⽤ SET 命令设置锁变量值时，每个客户端设置的值是⼀个唯⼀值，⽤于标识客户端；

满⾜这三个条件的分布式命令如下： 

~~~c
SET lock_key unique_value NX PX 10000
~~~

**这样就通过 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。**

基于Redis实现分布式锁的缺点:

- **超时时间不好设置。**
- **Redis主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性。**

## 数据类型与底层数据结构

### String

最基本的 key-value 结构。

使用**SDS简单动态字符串**：

- **可以保存文本数据，还可以保存⼆进制数据。**
- **⽤len属性记录了字符串长度，获取字符串长度的时间复杂度是 O(1)**
- **拼接字符串之前会检查 SDS 空间是否满⾜要求，如果空间不够会自动扩 容，所以不会导致缓冲区溢出**

应用场景：

- 通常用来缓存整个JSON对象
- **常规计数**
- **分布式锁**
- **共享session：分布式存储用户会话**

### List

是简单的字符串列表，按照插⼊顺序排序，**可以从头部或尾部向 List 列表添加元素。**

在 Redis 3.2 版本之后，**List 数据类型底层数据结构就只由 quicklist 实现 了，替代了双向链表和压缩列表。**

应用场景：

- **消息队列：必须要满足三个需求，分别是**
- - 消息保序
  - 阻塞读取
  - 处理重复的消息：设置全局ID
  - 保证消息可靠性：开另一个List留存消息

- **缺陷：不⽀持多个消费者消费同⼀条消息，消费完就删除**

### Hash

**Hash 是⼀个键值对（key - value）集合**，其中 value 的形式如： value= [{field1，value1}，...{fieldN，valueN}] 。**Hash 特别适合⽤于存储对象。**

Hash 类型的**底层数据结构是由压缩列表或哈希表**实现的：

- 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 来实现了。

应用场景：

- 缓存对象
- **购物车**

### Set

**无序并唯⼀的键值集合**，它的存储顺序不会按照插入的先后顺序进行存储。

**底层数据结构是由哈希表或整数集合**实现的：

应用场景：

- **点赞**
- **共同关注、好友**
- **抽奖活动**

### Zset

Zset 类型（有序集合类型）相⽐于 Set 类型**多了⼀个排序属性 score**

Zset 类型的底层数据结构是**由压缩列表或跳表实现的：**

- 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由listpack来实现了

应用场景：

- **排行榜**
- **电话、姓名排序**

### BitMap

Bitmap，即**位图，是⼀串连续的⼆进制数组（0和1）**

- 通过**偏移量 （offset）定位元素**
- 节省空间，特别适合**⼀些数据量大且使用⼆值统计**的场景

应用场景：

- **签到统计**

### HyperLogLog

HyperLogLog 提供不精确的去重计数

应用场景：

- **百万级网页UV 计数**：百度搜索大概有多少条

### GEO

存储地理位置信息， 并对存储的信息进⾏操作。

GEO 类型**使⽤GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换**

应用场景：

- **滴滴打车**

### Stream

**Redis专门为消息队列设计的数据类型**

Stream 可以使⽤ **XGROUP 创建消费组**

- **创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。**
- - 即同⼀个消费组⾥的消费者不能消费同⼀条消息。
  - 不同消费组的消费者可以消费同⼀条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）

- Streams会**自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息**，直到消费者使用XACK命令通知 Streams“消息已经处理完成”。

**缺陷：**

- 可能会丢失消息：AOF刷盘数据丢失、主从复制数据丢失
- 消息不能大容量堆积：影响性能

### ----数据结构分割线----

哈希桶存放的是指向键值对数据的指针（dictEntry*），**保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象**

对象结构⾥包含的成员变量： 

- type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对 象、Set 对象和 Zset 对象）；
- encoding，标识该对象使⽤了哪种底层的数据结构； 
- **ptr，指向底层数据结构的指针。**

### SDS

区别：

- **C语言除了字符串的末尾之外，字符串里⾯不能含有 “\0” 字符，否则会误读**
- C语言不能保存像图⽚、⾳频、视频⽂化这样的⼆进制数据
- C 语⾔字符串的操作函数是不安全的，可能导致缓冲区溢出

### 链表

是⼀个**双向链表**

- list 结构为链表**提供了链表头指针 head、链表尾节点 tail、链表节点数量 len** 
- 以及可以**⾃定义实现的 dup、free、match 函数**。

**数据量少会使用压缩列表**：

最大特点：⼀种内存紧凑型的数据结构

- **是由连续内存块组成的顺序型数据结构，有点类似于数组**

- **缺陷：连锁更新问题**
- 压缩列表新增某个元素或修改某个元素时，如果空间不够，压缩列表占⽤的内存空间就需要重新分配。
- 当新插入的元素较大时，**可能会导致后续元素的 prevlen 占用空间都发生变化**，从而引起「连锁更新」问题，导致每个元素的 空间都要重新分配，造成访问压缩列表性能的下降。

- 在后来的版本中，新设计两种数据结构：**quicklist和 listpack**

### 哈希表

**Redis 采用了「链式哈希」来解决哈希冲突**

- **但是链表过长需要使用rehash来扩展大小**：有两个哈希表，插⼊的数据，都会写⼊到「哈希表 1」
- - 随着数据逐步增多，**触发了 rehash 操作，这个过程分为三步**： 
  - **给「哈希表 2」 分配空间，⼀般会⽐「哈希表 1」 ⼤⼀倍（两倍的意思）；**
  - **将「哈希表 1 」的数据迁移到「哈希表 2」 中；** 
  - **迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈 希表 1」，然后在「哈希表 2」 新创建⼀个空⽩的哈希表，为下次 rehash 做准备。**

- **渐进式rehash**：
- - 在 rehash 进⾏期间，每次哈希表元素进⾏新增、删除、查找或者更新操作 时，Redis 除了会执⾏对应的操作之外，还会顺序将「哈希表 1 」中索引位 置上的所有 key-value 迁移到「哈希表 2」上

### 整数集合

保存元素的容器是⼀个 contents 数组

升级规则：将⼀个新元素加⼊到整数集合里面， 如果新元素的类型（int32_t）⽐整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进⾏升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，**好处是节省内存资源**。

### 跳表（重）

**只有 Zset 对象的底层实现⽤到了跳表，跳表的优势是能⽀持平均 O(logN) 复杂度的节点查找**

- **跳表是在链表基础上改进过来的，实现了⼀种 「多层」的有序链表**

如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，**使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。**

可以看到，这个查找过程就是**在多个层级上跳来跳去，最后定位到元素。当数据量很⼤时，跳表的查找复杂度就是 O(logN)。**

![img](C:\Users\lsl31\Desktop\MarkDown图库\3层跳表-跨度.png)

------

在遍历某⼀层的跳表节点时，会⽤跳表节点中的SDS类型的元素权重来进⾏判断，共有两个判断条件：

- **如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下⼀个节点。** 
- **如果当前节点的权重「等于」要查找的权重时，并且当前节点的SDS类型 数据「小于」要查找的数据时，跳表就会访问该层上的下⼀个节点。**

如果上面两个条件都不满⾜，**或者下⼀个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下⼀层指针**

- **跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)**
- **跳表在创建节点的时候，随机生成每个节点的层数**

------

跳表VS红黑树：

- **从内存占用上来比较，跳表比平衡树更灵活⼀些。**
- **在做范围查找的时候，跳表比平衡树操作要简单。**
- **从算法实现难度上来比较，跳表比平衡树要简单得多。**

### quicklist

**quicklist 就是「双向链表 + 压缩列表」组合**

**因为⼀个 quicklist 就是⼀个链表，链表中的每个元素又是⼀个压缩列表**

- 通过**控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题**。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。

### listpack

它最⼤特点是 **listpack 中每个节点不再包含前⼀个节点的长度了**

- 压缩列表每个节点**正因为需要保存前⼀个节点的长度字段，就会有连锁更新的隐患**。

- 压缩列表的 **entry 保存 prevlen 是为了实现节点从后往前遍历**，知道前⼀个节点的⻓度，就可以计算前⼀个节点的偏移量。

## 持久化

### AOF日志

存写操作命令到日志的持久化方式，就是 Redis 里的 **AOF(\*Append Only File\*)**

- **注意只会记录写操作命令**

- **默认是不开启的，需要我们修改 `redis.conf` 配置文件中的以下参数**

先写命令再写日志的好处：

- **避免额外的检查开销**
- **不会阻塞当前写操作命令的执行**
- **缺点：有丢失的风险，可能阻塞下一条命令，因为将命令写入到日志的这个操作也是在主进程完成的**

#### AOF刷盘机制

**AOF日志刷盘的主要步骤：**

1. Redis 执行完写操作命令后，会将命令**追加到 `server.aof_buf` 缓冲区**
2. 通过 write() 系统调用，将 aof_buf 缓冲区的数据**写入内核缓冲区 page cache**
3. 具体内核缓冲区的数据什么时候**写入到硬盘**，由内核决定

**以下 3 种参数可填：**

- Always，这个单词的意思是「总是」，所以它的意思是**每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘**；
- Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，**先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；**
- No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，**先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。**

#### AOF重写机制

Redis **为了避免 AOF 文件越写越大，提供了 AOF 重写机制**

- **当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。**

- AOF 重写机制是**在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。**

- 在使用重写机制后，就会读取 name 最新的 value（键值对） ，**然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件，之前的第一个命令就没有必要记录了**

- 为什么不覆写原有的：**如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染**

#### AOF 后台重写

写入AOF日志是主进程，**重写是后台子进程完成的**

**父子进程关系：**

- 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，**操作系统会把主进程的「页表」复制一份给子进程**
- **页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。**

- **节约物理内存资源**，页表对应的页表项的属性会标记该物理内存的权限为**只读**。

- **（重点）当父子进程进行写操作会触发CPU的写保护中断，操作系统会进行物理内存的复制，重新设置内存映射关系，让父子内存权限设置为可读写，最后对内存进行写操作，这个过程被称为「写时复制(\*Copy On Write\*)」。**

<img src="C:\Users\lsl31\Desktop\MarkDown图库\d4cfac545377b54dd035c775603b4936.png" alt="img" style="zoom:67%;" />

**在发生写操作的时候，操作系统才会去复制物理内存**。防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。

触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。子进程重写过程中，主进程依然可以正常处理命令。

**主进程修改了已经存在 key-value，就会发生写时复制**，**注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的**。

------

**问题：**重写 AOF 日志过程中，如果主进程修改已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了怎么办呢？

Redis 设置了一个 **AOF 重写缓冲区**。**当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」。**

当子进程**完成 AOF 重写工作，会发出异步信号，**

**主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：**

- **将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中**，使得新旧两个 AOF 文件所保存的数据库状态一致； 
- 新的 AOF 的文件进行改名，**覆盖现有的 AOF 文件。**

------

### RDB快照

RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，**RDB 文件的内容是二进制数据**。

- **Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以**

Redis 提供了两个命令来生成 RDB 文件，**分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：**

- save在主线程会阻塞线程
- bgsave创建子线程

Redis 的快照是**全量快照**，**也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。**

- **缺点：如果 Redis 出现宕机等情况，则意味着可能丢失数据**

#### 执行快照时，数据能被修改吗？

执行 bgsave 过程中，由于是交给子进程：**写时复制技术**

- 如果主线程（父进程）要**修改共享数据里的某一块数据（比如键值对 A）时，就会发生写时复制，于是这块数据的物理内存就会被复制一份（键值对 A'）**，然后主线程在这个数据副本（键值对 A'）进行修改操作。与此同时，**bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件。**

- **缺点：主线程修改了内存数据，子线程写入到RDB文件都是原本数据。如果系统崩溃就会丢失数据**

### AOF和RDB合体

Redis 4.0 提出的，该方法**叫混合使用 AOF 日志和内存快照，也叫混合持久化。**

- 混合持久化工作在 **AOF 日志重写过程**。

**工作流程：**

1. 当开启了混合持久化时，在 AOF 重写日志时，**fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件**
2. 然后主线程处理的操作命令会被记录在重写缓冲区里，**重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件**
3. 写入完成后**通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。**

好处在于：

- 重启 Redis 加载数据的时候，由于**前半部分是 RDB 内容，这样加载的时候速度会很快。** 
- 加载**后半部分的 AOF 内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。**

### 大 Key 对持久化有什么影响？

- **引发网络阻塞**
- **客户端超时阻塞**
- **阻塞工作线程**
- **内存分布不均匀**

**AOF日志：**

- **当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久**
- 当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数不影响。
- No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程

**AOF重写和RDB快照：**

- AOF 日志文件的大小会很大，那么很快就会触发 **AOF 重写机制**。

- **大 Key会导致页表很大， `fork()` 函数复制页表需要很长时间从而阻塞主进程**
- **主线程对大Key修改会发生写时复制，复制物理内存会很长时间从而阻塞**

## 过期删除和内存淘汰

Redis 是**可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除**

### 如何判定 key 已过期了？

Redis 会把该 key 带上过期时间存储到一个**过期字典**，**保存了数据库中所有 key 的过期时间**

**Redis 首先检查该 key 是否存在于过期字典中：** 

- 如果不在，则正常读取键值； 
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

### 过期删除策略有哪些？

常见的三种过期删除策略： 

- **定时删除：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作；** 
- - 优点：保证过期 key 会被尽快删除，内存友好
  - 缺点：删除过期 key 可能会占用相当一部分 CPU 时间，影响性能
- **惰性删除：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key；**
- - 优点：对CPU很友好
  - 缺点：只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费 
- **定期删除：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key；**
- - 优点：端水大师
  - 缺点：端水反而哪都不行

### Redis 过期删除策略是什么？

**Redis 选择「惰性删除+定期删除」这两种策略配和使用**

### ----------------------------------------------------------

### 内存淘汰策略

**当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行**

可以通过参数 `maxmemory <bytes>` 来设定最大运行内存

### Redis 内存淘汰策略有哪些？

Redis 内存淘汰策略共有八种，**这8种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。**

**1、不进行数据淘汰的策略**

- 它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入
- 不淘汰任何数据，但是**如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作**。

**2、进行数据淘汰的策略**

又可以**细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。**

### LRU 算法和 LFU 算法有什么区别？

- **LRU 全称是 Least Recently Used 翻译为最近最少使用，会选择淘汰最近最少使用的数据。**
- **LFU 全称是 Least Frequently Used 翻译为最近最不常用，LFU 算法是根据数据访问次数来淘汰数据的**

## 高可用（主从复制、哨兵、集群）

### 主从复制

主从复制模式保证多台服务器的数据一致性，**且主从服务器之间采用的是「读写分离」的方式。**

主服务器可以进行读写操作，**当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读**

- **所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器**，这样就使得主从服务器的数据是一致的。

#### 第一次同步

可分为三个阶段： 

1. **第一阶段是建立链接、协商同步** 
2. **第二阶段是主服务器同步数据给从服务器**
3. **第三阶段是主服务器发送新写操作命令给从服务器**

