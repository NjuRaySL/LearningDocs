# Redis

## 基础

### Redis概念

Redis 是⼀种**基于内存的数据库**

**读写速度非常快，常用于缓存，消息队列、分布式锁等场景**。

Redis 提供了多种数据类型：，**⽐如 String(字符串)、 Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、 HyperLogLog（基数统计）、GEO（地理信息）**、Stream（流）。

**Redis 还支持事务 、持久化**、Lua 脚本、**多种集群方案**（主从复制模式、哨兵模式、切⽚机群模式）、发布/订阅模式，**内存淘汰机制、过期删除机制**等等。

### Redis 和 Memcached 有什么区别？

- **Redis支持的数据类型更丰富**
- **Redis支持数据的持久化，重启后可以继续使用**
- **Redis支持原生集群模式**
- **Redis支持Lua脚本，发布/订阅模型和事务等**

### Redis 作为 MySQL 的缓存？

Redis 具备**「⾼性能」和「⾼并发」**两种特性

- **直接访问 Redis 能够承受的请求是远远⼤于直接访问 MySQL 的**，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样⽤户的⼀部分请求会直接到缓存这⾥而不用经过数据库

### Redis线程模型

Redis单线程指的是**「接收客户端请求->解析请求 ->进⾏数据读写等操作->发送数据给客户端」这个过程是由⼀个线程（主线程）来完成的**

Redis并不是单线程的：

- Redis为「关闭⽂件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理**

- **异步释放Redis也就是 lazyfree线程用来删除大Key**

### 为什么Redis这么快（重）

- **大部分操作都在内存完成**，Redis 瓶颈可能是机器的内存或者网络带宽，不是CPU
- **采⽤单线程模型可以避免了多线程之间的竞争**
- **采⽤了 I/O 多路复⽤机制处理⼤量的客户端 Socket 请求**

### 之前单线程/之后多线程

**之前单线程原因：**

- CPU 并不是制约Redi 性能表现的瓶颈所在
- 多线程增加复杂度，资源消耗难维护，可能出现死锁

**之后多线程原因：**

- 因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在⽹络 I/O 的处理上。**为了提⾼⽹络 I/O 的并⾏度，Redis 6.0 对于⽹络 I/O 采⽤多线程来处理**

- **对于命令的执⾏，Redis 仍然使用单线程来处理**

### 如何设计⼀个缓存策略，可以动态缓存热点数据

总体思路：

**通过数据最新访问时间来做排名，并过滤 掉不常访问的数据，只留下经常访问的数据。**

### 常⻅的缓存更新策略？

常见的缓存更新策略共有3种： 

- **Cache Aside（旁路缓存）策略；** 
- **Read/Write Through（读穿 / 写穿）策略；** 
- **Write Back（写回）策略；**

------

Cache Aside（旁路缓存）策略：

- 写策略：**先更新数据库中的数据，再删除缓存中的数据（注意顺序）**
- 读策略：**如果读取的数据命中了缓存，则直接返回数据； 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写⼊到 缓存，并且返回给⽤户**。

Read/Write Through（读穿 / 写穿）策略：

- **Read Through 策略：**先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组 件负责从数据库查询数据，并将结果写⼊到缓存组件，最后缓存组件将数据返 回给应⽤
- **Write Through 策略：**
- - 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应⽤程序更新完成。 
  - 如果缓存中数据不存在，直接更新数据库，然后返回

Write Back（写回）策略：

- **在更新数据的时候，只更新缓存，同时将缓存数据设 置为脏的，然后立马返回，并不会更新数据库。**

### Redis 如何实现延迟队列？

在 Redis可以使⽤有序集合（ZSet）的⽅式来实现延迟消息队列的

ZSet **有⼀个 Score 属性可以⽤来存储延迟执行的时间**

### Redis 的大key 如何处理？

大key 并不是指 key 的值很大，**而是 key 对应的 value 很⼤。**

**如何找到大key？**

- redis-cli --bigkeys 查找大key
- 使用SCAN命令查找大key

**如何删除大key?**

- **分批次删除**
- **异步删除：放在异步线程删除，不会阻塞**

### Redis管道有什么用？

⼀种批处理技术，**一次处理多个 Redis 命令**，从⽽提⾼整个交互的性能

**可以解决多个命令执行时的网络等待**

### Redis 事务支持回滚吗？

**Redis 中并没有提供回滚机制**，

- 虽然 Redis 提供了 DISCARD 命令，但是这个命令**只能⽤来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果**
- **已经执行的命令没办法回退，不能保证原子性**

### 如何用Redis实现分布式锁的

**分布式锁是用于分布式环境下并发控制的⼀种机制，⽤于控制某个资源在同⼀时刻只能被⼀个应用所使用**

Redis的SET命令有个 NX 参数可以实现「key不存在才插⼊」，所以可以用它来实现分布式锁： 

- **如果 key 不存在，则显示插⼊成功，可以⽤来表示加锁成功；** 
- **如果 key 存在，则会显示插⼊失败，可以⽤来表示加锁失败。**

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满⾜三个条件。 

- **加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作**，但需要以原子操作的⽅式完成，所以，我们使用SET命令带上 NX 选项来实现加锁； 
- **锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁⼀直无法释放**，所以，我们在SET命令执⾏时加上EX/PX选项，设置其过期时间； 
- **锁变量的值需要能区分来⾃不同客户端的加锁操作，以免在释放锁时，出现误释放操作**，所以，我们使⽤ SET 命令设置锁变量值时，每个客户端设置的值是⼀个唯⼀值，⽤于标识客户端；

满⾜这三个条件的分布式命令如下： 

~~~c
SET lock_key unique_value NX PX 10000
~~~

**这样就通过 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。**

基于Redis实现分布式锁的缺点:

- **超时时间不好设置。**
- **Redis主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性。**

## 数据类型与底层数据结构

### String

最基本的 key-value 结构。

使用**SDS简单动态字符串**：

- **可以保存文本数据，还可以保存⼆进制数据。**
- **⽤len属性记录了字符串长度，获取字符串长度的时间复杂度是 O(1)**
- **拼接字符串之前会检查 SDS 空间是否满⾜要求，如果空间不够会自动扩 容，所以不会导致缓冲区溢出**

应用场景：

- 通常用来缓存整个JSON对象
- **常规计数**
- **分布式锁**
- **共享session：分布式存储用户会话**

### List

是简单的字符串列表，按照插⼊顺序排序，**可以从头部或尾部向 List 列表添加元素。**

在 Redis 3.2 版本之后，**List 数据类型底层数据结构就只由 quicklist 实现 了，替代了双向链表和压缩列表。**

应用场景：

- **消息队列：必须要满足三个需求，分别是**
- - 消息保序
  - 阻塞读取
  - 处理重复的消息：设置全局ID
  - 保证消息可靠性：开另一个List留存消息

- **缺陷：不⽀持多个消费者消费同⼀条消息，消费完就删除**

### Hash

**Hash 是⼀个键值对（key - value）集合**，其中 value 的形式如： value= [{field1，value1}，...{fieldN，valueN}] 。**Hash 特别适合⽤于存储对象。**

Hash 类型的**底层数据结构是由压缩列表或哈希表**实现的：

- 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 来实现了。

应用场景：

- 缓存对象
- **购物车**

### Set

**无序并唯⼀的键值集合**，它的存储顺序不会按照插入的先后顺序进行存储。

**底层数据结构是由哈希表或整数集合**实现的：

应用场景：

- **点赞**
- **共同关注、好友**
- **抽奖活动**

### Zset

Zset 类型（有序集合类型）相⽐于 Set 类型**多了⼀个排序属性 score**

Zset 类型的底层数据结构是**由压缩列表或跳表实现的：**

- 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由listpack来实现了

应用场景：

- **排行榜**
- **电话、姓名排序**

### BitMap

Bitmap，即**位图，是⼀串连续的⼆进制数组（0和1）**

- 通过**偏移量 （offset）定位元素**
- 节省空间，特别适合**⼀些数据量大且使用⼆值统计**的场景

应用场景：

- **签到统计**

### HyperLogLog

HyperLogLog 提供不精确的去重计数

应用场景：

- **百万级网页UV 计数**：百度搜索大概有多少条

### GEO

存储地理位置信息， 并对存储的信息进⾏操作。

GEO 类型**使⽤GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换**

应用场景：

- **滴滴打车**

### Stream

**Redis专门为消息队列设计的数据类型**

Stream 可以使⽤ **XGROUP 创建消费组**

- **创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。**
- - 即同⼀个消费组⾥的消费者不能消费同⼀条消息。
  - 不同消费组的消费者可以消费同⼀条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）

- Streams会**自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息**，直到消费者使用XACK命令通知 Streams“消息已经处理完成”。

**缺陷：**

- 可能会丢失消息：AOF刷盘数据丢失、主从复制数据丢失
- 消息不能大容量堆积：影响性能

### ----数据结构分割线----

哈希桶存放的是指向键值对数据的指针（dictEntry*），**保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象**

对象结构⾥包含的成员变量： 

- type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对 象、Set 对象和 Zset 对象）；
- encoding，标识该对象使⽤了哪种底层的数据结构； 
- **ptr，指向底层数据结构的指针。**

### SDS

区别：

- **C语言除了字符串的末尾之外，字符串里⾯不能含有 “\0” 字符，否则会误读**
- C语言不能保存像图⽚、⾳频、视频⽂化这样的⼆进制数据
- C 语⾔字符串的操作函数是不安全的，可能导致缓冲区溢出

### 链表

是⼀个**双向链表**

- list 结构为链表**提供了链表头指针 head、链表尾节点 tail、链表节点数量 len** 
- 以及可以**⾃定义实现的 dup、free、match 函数**。

**数据量少会使用压缩列表**：

最大特点：⼀种内存紧凑型的数据结构

- **是由连续内存块组成的顺序型数据结构，有点类似于数组**

- **缺陷：连锁更新问题**
- 压缩列表新增某个元素或修改某个元素时，如果空间不够，压缩列表占⽤的内存空间就需要重新分配。
- 当新插入的元素较大时，**可能会导致后续元素的 prevlen 占用空间都发生变化**，从而引起「连锁更新」问题，导致每个元素的 空间都要重新分配，造成访问压缩列表性能的下降。

- 在后来的版本中，新设计两种数据结构：**quicklist和 listpack**

### 哈希表

**Redis 采用了「链式哈希」来解决哈希冲突**

- **但是链表过长需要使用rehash来扩展大小**：有两个哈希表，插⼊的数据，都会写⼊到「哈希表 1」
- - 随着数据逐步增多，**触发了 rehash 操作，这个过程分为三步**： 
  - **给「哈希表 2」 分配空间，⼀般会⽐「哈希表 1」 ⼤⼀倍（两倍的意思）；**
  - **将「哈希表 1 」的数据迁移到「哈希表 2」 中；** 
  - **迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈 希表 1」，然后在「哈希表 2」 新创建⼀个空⽩的哈希表，为下次 rehash 做准备。**

- **渐进式rehash**：
- - 在 rehash 进⾏期间，每次哈希表元素进⾏新增、删除、查找或者更新操作 时，Redis 除了会执⾏对应的操作之外，还会顺序将「哈希表 1 」中索引位 置上的所有 key-value 迁移到「哈希表 2」上

### 整数集合

保存元素的容器是⼀个 contents 数组

升级规则：将⼀个新元素加⼊到整数集合里面， 如果新元素的类型（int32_t）⽐整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进⾏升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，**好处是节省内存资源**。

### 跳表（重）

**只有 Zset 对象的底层实现⽤到了跳表，跳表的优势是能⽀持平均 O(logN) 复杂度的节点查找**

- **跳表是在链表基础上改进过来的，实现了⼀种 「多层」的有序链表**

如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，**使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。**

可以看到，这个查找过程就是**在多个层级上跳来跳去，最后定位到元素。当数据量很⼤时，跳表的查找复杂度就是 O(logN)。**

![img](C:\Users\lsl31\Desktop\MarkDown图库\3层跳表-跨度.png)

------

在遍历某⼀层的跳表节点时，会⽤跳表节点中的SDS类型的元素权重来进⾏判断，共有两个判断条件：

- **如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下⼀个节点。** 
- **如果当前节点的权重「等于」要查找的权重时，并且当前节点的SDS类型 数据「小于」要查找的数据时，跳表就会访问该层上的下⼀个节点。**

如果上面两个条件都不满⾜，**或者下⼀个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下⼀层指针**

- **跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)**
- **跳表在创建节点的时候，随机生成每个节点的层数**

------

跳表VS红黑树：

- **从内存占用上来比较，跳表比平衡树更灵活⼀些。**
- **在做范围查找的时候，跳表比平衡树操作要简单。**
- **从算法实现难度上来比较，跳表比平衡树要简单得多。**

### quicklist

**quicklist 就是「双向链表 + 压缩列表」组合**

**因为⼀个 quicklist 就是⼀个链表，链表中的每个元素又是⼀个压缩列表**

- 通过**控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题**。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。

### listpack

它最⼤特点是 **listpack 中每个节点不再包含前⼀个节点的长度了**

- 压缩列表每个节点**正因为需要保存前⼀个节点的长度字段，就会有连锁更新的隐患**。

- 压缩列表的 **entry 保存 prevlen 是为了实现节点从后往前遍历**，知道前⼀个节点的⻓度，就可以计算前⼀个节点的偏移量。

## 持久化

### AOF日志

存写操作命令到日志的持久化方式，就是 Redis 里的 **AOF(\*Append Only File\*)**

- **注意只会记录写操作命令**

- **默认是不开启的，需要我们修改 `redis.conf` 配置文件中的以下参数**

先写命令再写日志的好处：

- **避免额外的检查开销**
- **不会阻塞当前写操作命令的执行**
- **缺点：有丢失的风险，可能阻塞下一条命令，因为将命令写入到日志的这个操作也是在主进程完成的**

#### AOF刷盘机制

**AOF日志刷盘的主要步骤：**

1. Redis 执行完写操作命令后，会将命令**追加到 `server.aof_buf` 缓冲区**
2. 通过 write() 系统调用，将 aof_buf 缓冲区的数据**写入内核缓冲区 page cache**
3. 具体内核缓冲区的数据什么时候**写入到硬盘**，由内核决定

**以下 3 种参数可填：**

- Always，这个单词的意思是「总是」，所以它的意思是**每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘**；
- Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，**先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；**
- No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，**先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。**

#### AOF重写机制

Redis **为了避免 AOF 文件越写越大，提供了 AOF 重写机制**

- **当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。**

- AOF 重写机制是**在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。**

- 在使用重写机制后，就会读取 name 最新的 value（键值对） ，**然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件，之前的第一个命令就没有必要记录了**

- 为什么不覆写原有的：**如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染**

#### AOF 后台重写

写入AOF日志是主进程，**重写是后台子进程完成的**

**父子进程关系：**

- 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，**操作系统会把主进程的「页表」复制一份给子进程**
- **页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。**

- **节约物理内存资源**，页表对应的页表项的属性会标记该物理内存的权限为**只读**。

- **（重点）当父子进程进行写操作会触发CPU的写保护中断，操作系统会进行物理内存的复制，重新设置内存映射关系，让父子内存权限设置为可读写，最后对内存进行写操作，这个过程被称为「写时复制(\*Copy On Write\*)」。**

<img src="C:\Users\lsl31\Desktop\MarkDown图库\d4cfac545377b54dd035c775603b4936.png" alt="img" style="zoom:67%;" />

**在发生写操作的时候，操作系统才会去复制物理内存**。防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。

触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。子进程重写过程中，主进程依然可以正常处理命令。

**主进程修改了已经存在 key-value，就会发生写时复制**，**注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的**。

------

**问题：**重写 AOF 日志过程中，如果主进程修改已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了怎么办呢？

Redis 设置了一个 **AOF 重写缓冲区**。**当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」。**

当子进程**完成 AOF 重写工作，会发出异步信号，**

**主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：**

- **将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中**，使得新旧两个 AOF 文件所保存的数据库状态一致； 
- 新的 AOF 的文件进行改名，**覆盖现有的 AOF 文件。**

------

### RDB快照

RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，**RDB 文件的内容是二进制数据**。

- **Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以**

Redis 提供了两个命令来生成 RDB 文件，**分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：**

- save在主线程会阻塞线程
- bgsave创建子线程

Redis 的快照是**全量快照**，**也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。**

- **缺点：如果 Redis 出现宕机等情况，则意味着可能丢失数据**

#### 执行快照时，数据能被修改吗？

执行 bgsave 过程中，由于是交给子进程：**写时复制技术**

- 如果主线程（父进程）要**修改共享数据里的某一块数据（比如键值对 A）时，就会发生写时复制，于是这块数据的物理内存就会被复制一份（键值对 A'）**，然后主线程在这个数据副本（键值对 A'）进行修改操作。与此同时，**bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件。**

- **缺点：主线程修改了内存数据，子线程写入到RDB文件都是原本数据。如果系统崩溃就会丢失数据**

### AOF和RDB合体

Redis 4.0 提出的，该方法**叫混合使用 AOF 日志和内存快照，也叫混合持久化。**

- 混合持久化工作在 **AOF 日志重写过程**。

**工作流程：**

1. 当开启了混合持久化时，在 AOF 重写日志时，**fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件**
2. 然后主线程处理的操作命令会被记录在重写缓冲区里，**重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件**
3. 写入完成后**通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。**

好处在于：

- 重启 Redis 加载数据的时候，由于**前半部分是 RDB 内容，这样加载的时候速度会很快。** 
- 加载**后半部分的 AOF 内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。**

### 大 Key 对持久化有什么影响？

- **引发网络阻塞**
- **客户端超时阻塞**
- **阻塞工作线程**
- **内存分布不均匀**

**AOF日志：**

- **当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久**
- 当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数不影响。
- No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程

**AOF重写和RDB快照：**

- AOF 日志文件的大小会很大，那么很快就会触发 **AOF 重写机制**。

- **大 Key会导致页表很大， `fork()` 函数复制页表需要很长时间从而阻塞主进程**
- **主线程对大Key修改会发生写时复制，复制物理内存会很长时间从而阻塞**

## 过期删除和内存淘汰

Redis 是**可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除**

### 如何判定 key 已过期了？

Redis 会把该 key 带上过期时间存储到一个**过期字典**，**保存了数据库中所有 key 的过期时间**

**Redis 首先检查该 key 是否存在于过期字典中：** 

- 如果不在，则正常读取键值； 
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

### 过期删除策略有哪些？

常见的三种过期删除策略： 

- **定时删除：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作；** 
- - 优点：保证过期 key 会被尽快删除，内存友好
  - 缺点：删除过期 key 可能会占用相当一部分 CPU 时间，影响性能
- **惰性删除：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key；**
- - 优点：对CPU很友好
  - 缺点：只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费 
- **定期删除：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key；**
- - 优点：端水大师
  - 缺点：端水反而哪都不行

### Redis 过期删除策略是什么？

**Redis 选择「惰性删除+定期删除」这两种策略配和使用**

### ----------------------------------------------------------

### 内存淘汰策略

**当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行**

可以通过参数 `maxmemory <bytes>` 来设定最大运行内存

### Redis 内存淘汰策略有哪些？

Redis 内存淘汰策略共有八种，**这8种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。**

**1、不进行数据淘汰的策略**

- 它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入
- 不淘汰任何数据，但是**如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作**。

**2、进行数据淘汰的策略**

又可以**细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。**

### LRU 算法和 LFU 算法有什么区别？

- **LRU 全称是 Least Recently Used 翻译为最近最少使用，会选择淘汰最近最少使用的数据。**
- **LFU 全称是 Least Frequently Used 翻译为最近最不常用，LFU 算法是根据数据访问次数来淘汰数据的**

## 高可用（主从复制、哨兵、集群）

### 主从复制

主从复制模式保证多台服务器的数据一致性，**且主从服务器之间采用的是「读写分离」的方式。**

主服务器可以进行读写操作，**当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读**

- **所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器**，这样就使得主从服务器的数据是一致的。

#### 第一次同步

可分为三个阶段： 

1. **第一阶段是建立链接、协商同步** 
2. **第二阶段是主服务器同步数据给从服务器**：采用RDB文件
3. **第三阶段是主服务器发送新写操作命令给从服务器**

- **主从复制期间的写操作命令并没有记录到刚刚生成的RDB ⽂件中，这时主从服务器间的数据就不⼀致了**。为了保证主从服务器的数据⼀致性，**主服务器在下面这三个时间间隙中将收到的写操作命令**，**写⼊到 replication buffer 缓冲区**⾥：
- - 主服务器⽣成 RDB ⽂件期间； 
  - 主服务器发送 RDB ⽂件给从服务器期间； 
  - 「从服务器」加载 RDB ⽂件期间；
- 完成 RDB 的载⼊后，会回复⼀个确认消息 主服务器。**主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器**，从服务器执⾏来⾃主服务器 replication buffer 缓冲区⾥发来的命令，这 时主从服务器的数据就⼀致了

#### 命令传播

主从服务器在完成第⼀次同步后，**双方之间就会维护⼀个 TCP 连接**

- 后续主服务器可以**通过这个连接继续将写操作命令传播给从服务器**
- **这个连接是长连接的**，⽬的是避免频繁的 TCP 连接和断开带来的性能开销

#### 分摊主服务器的压力

**从服务器可以有⾃⼰的从服务器**，我们可以把拥有从服务 器的从服务器当作经理⻆⾊

**它不仅可以接收主服务器的同步数据，⾃⼰也可 以同时作为主服务器的形式将数据同步给从服务器**

- 通过这种⽅式，主服务器⽣成 RDB 和传输 RDB 的压⼒可以**分摊到充当经理⻆⾊的从服务器。**

#### 增量复制

⽹络断开⼜恢复后，从主从服务器会采⽤增量复制 的⽅式继续同步，**也就是只会把⽹络断开期间主服务器接收到的写操作命令**

**主要有三个步骤：**

从服务器通知主服务器，主服务器告知从服务器即将使用增量复制，主服务器开始复制断线期间的指令

------

**主服务器怎么知道要将哪些增量数据发送给从服务器呢？**

- **repl_backlog_buffer，是⼀个「环形」缓冲区**，⽤于主从服务器断连后，从中找到差异的数据；
- **replication offset，标记上⾯那个缓冲区的同步进度**
- - 主从服务器都有各⾃的偏移量，主服务器使⽤ master_repl_offset 来记录自己「写」到的位置， 从服务器使用slave_repl_offset 来记录⾃⼰「读」到的位置。

1. 在主服务器进⾏命令传播时，**不仅会将写命令发送给从服务器，还会将写命令 写⼊到 repl_backlog_buffer 缓冲区⾥**
2. ⽹络断开后，当从服务器重新连上主服务器时，**从服务器会通过 psync 命令将 ⾃⼰的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器 执⾏哪种同步操作**
3. - 有数据就是增量复制
   - 没有数据就是全量复制
4. **因为是环形，写太快容易覆盖数据，所以缓冲区大小尽可能大一些**

#### 怎么判断 Redis 某个节点是否正常⼯作？

**通过互相的 ping-pong 心态检测机制**，如果有⼀半以上的节点去 ping ⼀个节点的时候没有 pong 回应，集群就会 认为这个节点挂掉了，会断开与这个节点的连接。

#### 如何如何应对主从数据不⼀致？

- 尽量保证主从节点间的⽹络连接状况良好
- 开发⼀个外部程序来监控主从节点间的复制进度

#### 主从切换如何减少数据丢失？

主从切换过程中，**产⽣数据丢失的情况有两种：** 

- **异步复制同步丢失** 
- **集群产生脑裂数据丢失**：**主节点网络断开，会选择一个新主节点，也就出现了脑裂。网络好了原来的主节点降级为从节点，请求全量复制，会清空之前本地的所有数据**

减少脑裂的数据丢的方案：

1. 当主节点发现「从节点下线的数量太多」，或者「⽹络延迟太⼤」的时候，那 么主节点会禁止写操作，客户端无法写入。
2. 网络好了之后，客户端写入都在新节点，所以数据全部清除也不影响。

#### 主从如何做到故障自动切换？

**哨兵机制**

### 哨兵机制

**实现主从节点故障转移。**

- 它会监测主节点是否存活，如果发现主节点挂了，**它就会选举⼀个从节点切换为主节点**
- 并且**把新主节点的相关信息通知给从节点和客户端**

哨兵其实是⼀个**运⾏在特殊模式下的 Redis 进程，它相当于是“观察者节点”。**

哨兵节点主要负责三件事情：**监控、选主、通知**

#### 如何判断主节点真的故障了？

哨兵会每隔 1 秒给所有主从节点发送 PING 命令

**没有在规定的时间内响应哨兵的 PING 命令，哨兵就会 将它们标记为「主观下线」。**

防止自身网络不好误判，**用多个节点部署成哨兵集群一起判断，投票**

#### 由哪个哨兵进行主从故障转移？

**在哨兵集群中选出⼀个leader，让leader来执⾏主从切换。**

- 哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者。
- 候选者会向其他哨兵发送命令，表明希望成为 Leader 来执⾏主从切换，并让所有其他哨兵对它进⾏投票。

- **为什么哨兵节点⾄少要有 3 个？：拿到半数以上的票**

#### 主从故障转移的过程是怎样的？

一共有四个步骤：

1. 选出新主节点：**根据优先级、复制进度和ID**
2. **将所有从节点指向新主节点**
3. **通知客户主节点已更换：通过 Redis 的发布者/订阅者机制来实现**
4. **将旧主节点变为从节点**

#### 哨兵集群是如何组成的？

哨兵集群的**组成也用到了**：**Redis 的发布者/订阅者机制**

## 缓存

### 缓存雪崩

**⼤量缓存数据在同⼀时间过期（失效）或者 Redis 故障宕机时**，**大量的用户请求直接访问数据库**

导致数据库的压⼒骤增，严重会造成系统崩溃，**这就是缓存雪崩的问题。**

1、缓存过期解决方法：

- 均匀设置过期时间：加上随机数
- **互斥锁：如果发现访问的数据不在 Redis ⾥，就加个互斥锁，保证同⼀时间内只有⼀个请求来构建缓存**
- 后台更新缓存：**让缓存“永久有效”， 并将更新缓存的⼯作交由后台线程定时更新。**

在业务刚上线的时候，我们最好提前把数据缓起来，不是等待⽤户访问才来触发缓存构建

- **这就是所谓的缓存预热，后台更新缓存的机制刚好也适合⼲这 个事情。**

2、Redis宕机解决办法：

- **服务熔断或请求限流机制**
- **构建 Redis 缓存⾼可靠集群：利用主从节点切换**

### 缓存击穿

**缓存中热点数据过期了，⼤量的请求访问了该热点数据，就⽆法从缓存中读取，直接访问数据库**

数据库很容易就被⾼并发的请求冲垮，**这就是缓存击穿的问题。**

解决方案：

- **互斥锁方案：保证同⼀时间只有⼀个业务线程更新缓存**
- **不给热点数据设置过期时间，由后台异步更新缓存**

### 缓存穿透

**当⽤户访问的数据，既不在缓存中，也不在数据库中**

- 没办法构建缓存数据，来服务后续的请求

有大量这样的请求到来时， 数据库的压⼒骤增，**这就是缓存穿透的问题**

出现场景：

- **业务误操作导致数据删除**：查不到数据
- **黑客攻击**：故意访问数据不存在的业务

解决办法：

- **非法请求的限制**：在 API⼊⼝处我们要**判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在**，如果判断出是恶意请求就直接返回错误。
- **缓存空值或者默认值**：针对查询的数据，在Redis缓存中设置空值或者默认值，避免查询数据库
- **使用布隆过滤器快速判断数据是否存在：**
- - 在**写入数据库时**用过滤器做标记
  - 在用户请求到来时，**业务线程确认缓存失效后，快速判断数据是否存在**，不存在就不查数据库
  - 即使发⽣了缓存穿透，⼤量请求只会查询 Redis 和布隆过滤器

布隆过滤器由**「初始值都为 0 的位图数组」和「 N 个哈希函数」**两部分组成。

- 当应⽤要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置 的值是否全为 1，**只要有⼀个为 0，就认为数据 x 不在数据库中。**
- **存在哈希冲突，可能出现误判。**
- 过滤器存在不一定数据库存在，**但是过滤器不存在那么数据库一定不存在**

## Redis与数据库一致性

- 先更新数据库，再更新Redis
- 先更新Redis，再更新数据库

都会出现**两个线程同时更新**的并发问题**导致数据不一致**

- 先删除缓存，再更新数据库
- A把20改为21，删除缓存在更新数据库时，B读数据库回写缓存，导致不一致

**两个线程在「读 + 写」并发的时候数据不一致**

- 先更新数据库，再删除缓存
- 缓存没数据，A读20写缓存，这时候B更新数据库21写21，然后A写20，导致不一致

在实际中，**这个问题出现概率低**，**因为缓存的写⼊通常要远远快于数据库的写⼊**，确保万⽆⼀失，**还给缓存数据加上了「过期时间」**

------

1、「先更新数据库，再删除缓存」虽然保证了数据库与缓存的数据⼀致，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。

**采⽤「更新数据 库 + 更新缓存」的⽅案：**

- **在更新缓存前先加个分布式锁，保证同⼀时间只运⾏⼀个请求更新缓存**
- **在更新完缓存时，给缓存加上较短的过期时间，这样即时出现缓存不⼀致的情况，缓存的数据也会很快过期**

2、「先更新数据库，再删除缓存」可能删除缓存会失败该怎么办？

- **消息队列重试机制。** 
- **订阅 MySQL binlog，再操作缓存**：订阅修改数据库的日志，拿到数据进行删除操作
- 为什么是删除缓存，⽽不是更新缓存呢？：**删除缓存的代价和开销小**

## Redis Cluster集群

如果你的项目用到了 Redis 的话（大部分人的项目都用到了 Redis 来做分布式缓存）

- 为了能比别人更有亮点，**Redis Cluster 是一个不错的选择。**

### 为什么需要 Redis Cluster？

高并发场景下，使用 Redis 主要会遇到的两个问题：

- **缓存的数据量太大**
- **并发量要求太大** 

主从复制和 Redis Sentinel 这两种方案本质:

- **通过增加主库（master）的副本 （slave）数量**的方式来提高 Redis 服务的整体可用性和读吞吐量
- **都不支持横向扩展来缓解写压力以及解决缓存数据量过大**的问题。

通常建议使用 **Redis 切片集群** 这种方案，**更能满足高并发场景下分布式缓存的要求。**

- **部署多台Redis主节点（master），这些节点之间平等，并没有主从之说**，同时对外提供读/写服务。

- **缓存的数据库相对均匀地分布在这些 Redis 实例上**
- **客户端的请求通过路由规则转发到目标 master 上**

- **通过 主从复制给每个 master 配置一个或者多个从节点（slave）保证高可用**

------

**优点：**

- **Redis Cluster 通过 分片（Sharding） 来进行数据管理**，
- **提供 主从复制（Master Slave Replication）、故障转移（Failover） 等开箱即用的功能**
- **可以非常方便地帮 助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。**

**Redis Cluster 的动态扩容和缩容是其最大的优势（重要）**

### 一个最基本的 Redis Cluster 架构是怎样的？

**Redis Cluster 至少需要 3 个 master 以及 3 个 slave**，也就是说每 个 master 必须有 1 个 slave。master 和 slave 之间做主从复制，slave 会实时同步 master 上的数据。

- 这里的 slave **除了可以用来保障 master 的高可用之外，还可 以对外提供读服务。**

- 如果 master 只有一个 slave 的话，**master 宕机之后就直接使用这个 slave 替代**

**如果宕机的 master 无 slave 的话，为了保障集群的完整性，保证所有的哈希槽都指派 给了可用的 master ，整个集群将不可用**

### Redis Cluster 是如何分片的？

**类似的问题：** 

● Redis Cluster 中的数据是如何分布的？ 

● 如何确定给定 key 的应该分布到哪个哈希槽中？

**Redis Cluster没用一致性哈希，采用的是哈希槽分区 ，每个键值对都属于一个 hash slot（哈希槽）。**

------

**分片流程：**

**1、分哈希槽：**假设集群有 3 个 Redis 节点组成，每个节点负责整个集群的一部分数据，哈希槽可能是这样分配的（这里只是演示，实际效果可能会有差异）： 

- Node 1 ： 0 - 5500 的 hash slots 
- Node 2 ： 5501 - 11000 的 hash slots 
- Node 3 ： 11001 - 16383 的 hash slots

**2、客户端找节点：**客户端连接 Redis Cluster 中任意一个 master 节点即可访问 Redis Cluster 的数据，**当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标节点。**

**3、返回给客户端消息：**如果哈希槽确实是当前节点负责，那就直接响应客户端的请求返回结果，如果不由当前节点负责，就会返回 -MOVED 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息。

------

**为什么还会存在找错节点的情况呢？根据公式计算难道还会出错？**

-  Redis Cluster 内部可能重新分配哈希槽比如扩容缩容，客户端缓存的哈希槽分配信息有误。

### 为什么 Redis Cluster 的哈希槽是 16384 个?

65536 个固然可以确保每个主节点有足够的哈希槽，但其占用的空间太大。 而且，Redis Cluster 的主节点通常不会扩展太多，16384 个哈希槽完全足够用了。

这里实际就是通过 bitmap 这种数据结构维护的哈希槽信息，每一个 bit 代表一个哈希 槽，每个 bit 只能存储 0/1 。如果该位为 1，表示这个哈希槽是属于这个节点。

![image-20240809165828036](C:\Users\l50039653\Desktop\Doc\Pics\image-20240809165828036.png)

最后，总结一下 Redis Cluster 的哈希槽的数量选择 16384 而不是 65536 的主要原因： 

- 哈希槽太大会导致心跳包太大，消耗太多带宽； 
- 哈希槽总数越少，对存储哈希槽信息的 bitmap 压缩效果越好； 
- Redis Cluster 的主节点通常不会扩展太多，16384 个哈希槽已经足够用了。

### Redis Cluster 如何重新分配哈希槽？

如果你想自己手动调整的话，**Redis Cluster 也内置了相关的命令：**

### Redis Cluster 扩容缩容期间可以提供服务吗？

**Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。**

**为了能正常提供服务，提供了重定向机制：**

- **ASK 重定向 ：可以看做是临时重定向**，**后续查询仍然发送到旧节点。** 
- **MOVED 重定向 ：可以看做是永久重定向**，**后续查询发送到新节点。**

客户端向指定节点发送请求命令，从客户端的角度来看，ASK 重定向是下面这样的： 

1. 如果请求的 key 对应的**哈希槽还在当前节点的话，就直接响应客户端的请求。** 
2. 如果请求的 key 对应的哈希槽在迁移过程中，**但是请求的 key 还未迁移走的话，说 明当前节点任然可以处理当前请求，同样可以直接响应客户端的请求。** 
3. 如果客户端请求的 key 对应的哈希槽当前正在迁移至新的节点且请求的 key 已经 被迁移走的话，**就会返回 -ASK 重定向错误，告知客户端要将请求发送到哈希槽被迁移到的目标节点**。 -ASK 重定向错误信息中包含请求 key 迁移到的新节点的 信息。 
4. **客户端收到 -ASK 重定向错误后，将会临时（一次性）重定向，自动向新节点发 送一条 ASKING  命令。也就是说，接收 到 ASKING 命令的节点会强制执行一次请求，下次再来需要重新提前发送 ASKING 命令。** 
5. **新节点在收到 ASKING 命令后可能会返回重试错误（TRYAGAIN），因为可能存在 当前请求的 key 还在导入中但未导入完成的情况。** 
6. **客户端发送真正需要请求的命令。**
7. ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息，也就是说，客户端对正在迁移的相同哈希槽的请求依然会发送到旧节点而不是新节点。

### Redis Cluster 中的节点是怎么进行通信的？

Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然 要相互通信就要遵循一致的通信协议

- Redis Cluster 中的各个节点**基于 Gossip 协议 来进行通信共享信息**
- **每个 Redis 节点都维护了一份集群的状态信息**。

Redis Cluster 的节点之间会相互发送多种 Gossip 消息：

- **MEET ：**以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点。
- **PING/PONG ：**Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息， 来交换各个节点状态信息
- **FAIL ：**Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期 限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。

**有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了，Redis Cluster 相当于是内置了 Sentinel 机制**  
